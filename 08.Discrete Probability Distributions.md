---
title: "Discrete Probability Distributions(Bernoulli, Binomial, Poisson, and Geometric Distributions)"
---
# Discrete Probability Distributions(Bernoulli, Binomial, Poisson, and Geometric Distributions)

## Bernoulli Distribution
- **Definition**: A discrete random variable $X$ with probability mass function:
  - $p_X(1) = P(X = 1) = p$
  - $p_X(0) = P(X = 0) = 1 - p$
- **Indicator Function**：Let $E$ be an event in the sample space $S$. The Indicator Function $I_E$ is defined as:
  - $I_E(s) = 1$ if $s \in E$;
  - $I_E(s) = 0$ if $s \notin E$.
- **Expectation**: $E(X) = p$
- **Variance**: $\text{Var}(X) = p(1 - p)$

## Binomial Distribution
- **Definition**: $X \sim \text{Bin}(n,p)$
  
  A discrete random variable $X$ with probability mass function:
  - $p_X(k) = \binom{n}{k} p^k (1 - p)^{n-k}$
    
  where $n$ is the number of trials and $p$ is the probability of success.
- **Expectation**: $E(X) = np$
  - $E(X) = \sum_{k=0}^{n} k P(X = k) = \sum_{k=1}^{n} k \binom{n}{k} p^k (1 - p)^{n-k}$
- **Variance**: $\text{Var}(X) = np(1 - p)$
- **Properties**:
  - **Vandermonde's Identity**： $\binom{n+m}{k} = \sum_{i=0}^{k} \binom{n}{i} \binom{m}{k-i}$ for any non-negative integers $n$, $m$ and $k$
  - $X$, $Y$ are **independent** random variables, $X \sim \text{Bin}(n, p)$ and $Y \sim \text{Bin}(m, p)$, then $X + Y \sim \text{Bin}(n + m, p)$.
  - Sampling **with replacement** from a large population can be approximated by a Binomial distribution.

## Poisson Distribution
- **Definition**: $X \sim \text{Po}(\lambda)$

  A discrete random variable $X$ with probability mass function:
  - $p_X(k) = \frac{\lambda^k e^{-\lambda}}{k!}$
    
  where $\lambda$ is the rate parameter.
- **Expectation**: $E(X) = \lambda$
  - $E(X) = \sum_{k=0}^{\infty} k P(X = k) = \sum_{k=0}^{\infty} k \frac{\lambda^k e^{-\lambda}}{k!}$
- **Variance**: $\text{Var}(X) = \lambda$
- **Properties**:
  - Arises as the **limit of a Binomial** distribution when the **number of trials is large** and the probability of success of each trial is inversely proportional to the number of trials：
    - suppose that $X_n, n \geq 1$ is a sequence of random variables such that $X_n \sim \text{Binomial}(n, p_n)$, where $p_n \sim \frac{\lambda}{n}$ as $n \rightarrow \infty$ (that is, $\lim_{n \rightarrow \infty} (n p_n) = \lambda$).
  - $X$ and $Y$ are independent random variables, $X \sim \text{Poisson}(\lambda)$ and $Y \sim \text{Poisson}(\mu)$, then $X + Y \sim \text{Poisson}(\lambda + \mu)$.

## Geometric Distribution
- **Definition**: $X \sim \text{Geom}(p)$

  A discrete random variable \( X \) with probability mass function:
  - $p_X(k) = (1 - p)^{k-1} p$
  
  where $p$ is the probability of success.
- **Expectation**: $E(X) = \frac{1}{p}$
  
  - $E(X) = \sum_{k=1}^{\infty} k P(X = k) = \sum_{k=1}^{\infty} k (1 - p)^{k-1} p = p \sum_{k=1}^{\infty} \left[ - \frac{\mathrm{d}}{\mathrm{d}p} (1-p)^k \right]$


- **Variance**: $\text{Var}(X) = \frac{1 - p}{p^2}$
  
- **Properties**:
  - Memoryless property: $P(X-n = k | X > n) = P(X = k)$
    - $P(X > n + k | X > n) = P(X > k)$
  - Minimum of two independent Geometric random variables: $X$ and $Y$ are independent random variables, $X \sim \text{Geom}(p)$ and $Y \sim \text{Geom}(q)$, then
    
$$
\text{min} \lbrace X, Y\rbrace \sim \text{Geom}(1 - (1 - p)(1 - q)).
$$
## Relevant important calculation formulas
- $\sum_{k=0}^{\infty} \frac{\lambda^k}{k!} = e^{\lambda}$
  
- $\sum_{k=0}^{\infty} ar^k = \frac{a}{1 - r}$
  
- $\sum_{i=0}^{k} \binom{k}{i} a^{i}b^{k-i} = (a+b)^k$
  
- $-\sum_{k=1}^{\infty} \frac{x^{k}}{k} = \ln(1-x)$, for $\|x\| < 1$
