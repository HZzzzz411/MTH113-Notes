# Continuous Probability Distributions (Uniform, Normal, and Exponential Distributions)

## Uniform Distribution
- **Definition**: A continuous random variable $S$ has a Uniform distribution on the interval $[a, b]$ if its probability density function (pdf) is:

$$
  f_X(x) = \begin{cases} 
  \frac{1}{b-a} & \text{if } x \in [a, b] \\
  0 & \text{otherwise}
  \end{cases}
$$
  
- **Cumulative Distribution Function (cdf)**:
  \[
  F_X(x) = \begin{cases} 
  0 & \text{if } x \leq a \\
  \frac{x-a}{b-a} & \text{if } x \in [a, b] \\
  1 & \text{if } x \geq b
  \end{cases}
  \]
- **Expectation**: \( E(X) = \frac{a + b}{2} \)
- **Variance**: \( \text{Var}(X) = \frac{(b - a)^2}{12} \)

## Normal Distribution
- **Definition**: A continuous random variable \( X \) has a Normal distribution with parameters \( \mu \) and \( \sigma^2 \) if its pdf is:
  \[
  f_X(x) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
  \]
- **Standard Normal Distribution**: \( Z \sim N(0, 1) \) with pdf:
  \[
  \phi(z) = \frac{1}{\sqrt{2\pi}} e^{-\frac{z^2}{2}}
  \]
  and cdf:
  \[
  \Phi(z) = \int_{-\infty}^{z} \phi(y) \, dy
  \]
- **Properties**:
  - Symmetry: \( \Phi(-z) = 1 - \Phi(z) \)
  - Linear transformations: If \( X \sim N(\mu, \sigma^2) \), then \( \frac{X - \mu}{\sigma} \sim N(0, 1) \)
  - Sum of independent Normal variables: If \( X \sim N(\mu_1, \sigma_1^2) \) and \( Y \sim N(\mu_2, \sigma_2^2) \), then \( X + Y \sim N(\mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2) \)
- **Central Limit Theorem**: The sum of a large number of independent and identically distributed random variables tends to be normally distributed.

## Exponential Distribution
- **Definition**: A continuous random variable \( X \) has an Exponential distribution with parameter \( \lambda \) if its pdf is:
  \[
  f_X(x) = \begin{cases} 
  \lambda e^{-\lambda x} & \text{if } x \geq 0 \\
  0 & \text{otherwise}
  \end{cases}
  \]
- **Cumulative Distribution Function (cdf)**:
  \[
  F_X(x) = \begin{cases} 
  0 & \text{if } x \leq 0 \\
  1 - e^{-\lambda x} & \text{if } x \geq 0
  \end{cases}
  \]
- **Expectation**: \( E(X) = \frac{1}{\lambda} \)
- **Variance**: \( \text{Var}(X) = \frac{1}{\lambda^2} \)
- **Memoryless Property**: \( P(X > t + s | X > t) = P(X > s) \)
- **Minimum of Independent Exponential Variables**: If \( X_1 \sim \text{Exp}(\lambda_1) \) and \( X_2 \sim \text{Exp}(\lambda_2) \), then \( \min(X_1, X_2) \sim \text{Exp}(\lambda_1 + \lambda_2) \)

## Key Terms and Concepts
- Uniform distribution
- Normal distribution
- Standard Normal distribution
- Central Limit Theorem
- Exponential distribution
- Memoryless property
- Cumulative distribution function (cdf)
- Probability density function (pdf)
- Expectation
- Variance
