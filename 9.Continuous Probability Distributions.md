# Continuous Probability Distributions (Uniform, Normal, and Exponential Distributions)

## Uniform Distribution: $X \sim \text{U}([a,b])$
- **Definition**: A continuous random variable $S$ has a Uniform distribution on the interval $[a, b]$ if its probability density function (pdf) is:

$$
  f_X(x) = \begin{cases} 
  \frac{1}{b-a} & \text{if } x \in [a, b] \\
  0 & \text{otherwise}
  \end{cases}
$$
  
- **Cumulative Distribution Function (cdf)**:
  
$$
  F_X(x) = \int_{\infty}^{x} f_{X}(y)dy = \begin{cases} 
  0 & \text{if } x \leq a \\
  \frac{x-a}{b-a} & \text{if } x \in [a, b] \\
  1 & \text{if } x \geq b
  \end{cases}
$$
- **Expectation**: $E(X) = \frac{a + b}{2}$
- **Variance**: $\text{Var}(X) = \frac{(b - a)^2}{12}$

## Normal Distribution: $X \sim \mathcal{N}(\mu, \sigma^2)$
- **Definition**: A continuous random variable $X$ has a Normal distribution with parameters $\mu$ and $\sigma^2$ if its pdf is:

$$
  f_X(x) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
$$
- **Standard Normal Distribution**: $Z \sim \mathcal{N}(0, 1)$ with
  
  - pdf: $\phi(z) = \frac{1}{\sqrt{2\pi}} e^{-\frac{z^2}{2}}$

  - cdf: $\Phi(z) = \int_{-\infty}^{z} \phi(y) dy$
  
- **Properties**:
  - Symmetry: $\Phi(-x) = 1 - \Phi(x)$
  - Linear transformations: If $X \sim \mathcal{N}(\mu, \sigma^2)$, then $\frac{X - \mu}{\sigma} \sim \mathcal{N}(0, 1)$
  - Sum of independent Normal variables: $X$, $Y$ are independent random variables, $X \sim \mathcal{N}(\mu_1, \sigma_1^2)$ and $Y \sim \mathcal{N}(\mu_2, \sigma_2^2)$, then $X + Y \sim \mathcal{N}(\mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2)$
- **Central Limit Theorem**: Let $X_1, X_2, \ldots, X_n$ be $n$ independent and identically distributed random variables with mean $\mu$ and variance $\sigma^2$. Then for large $n$, the following approximations hold:
  - $\frac{\sum_{i=1}^{n} X_i - n\mu}{\sqrt{n}\sigma} \approx Z \sim N(0,1)$, or equivalently, $\sum_{i=1}^{n} X_i \sim_{\text{approx}} N(n\mu, n\sigma^2)$

  
  - We also have:  $\frac{1}{n}\sum_{i=1}^{n} X_i \sim_{\text{approx}} N\left(\mu, \frac{\sigma^2}{n}\right).$

## Exponential Distribution
- **Definition**: A continuous random variable $X$ has an Exponential distribution with parameter $\lambda$ if its pdf is:
  \[
  f_X(x) = \begin{cases} 
  \lambda e^{-\lambda x} & \text{if } x \geq 0 \\
  0 & \text{otherwise}
  \end{cases}
  \]
- **Cumulative Distribution Function (cdf)**:
  \[
  F_X(x) = \begin{cases} 
  0 & \text{if } x \leq 0 \\
  1 - e^{-\lambda x} & \text{if } x \geq 0
  \end{cases}
  \]
- **Expectation**: $E(X) = \frac{1}{\lambda}$
- **Variance**: $\text{Var}(X) = \frac{1}{\lambda^2}$
- **Memoryless Property**: $P(X > t + s | X > t) = P(X > s)$
- **Minimum of Independent Exponential Variables**: If $X_1 \sim \text{Exp}(\lambda_1)$ and $X_2 \sim \text{Exp}(\lambda_2)$, then $\min(X_1, X_2) \sim \text{Exp}(\lambda_1 + \lambda_2)$
